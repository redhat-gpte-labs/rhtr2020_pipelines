:markup-in-source: verbatim,attributes,quotes

// Title comes from the workshop.yaml
// == Test Tekton Tasks

Before running our pipeline, you can test each single task by creating a *TaskRun*, another Tekton object that let us execute just one task rather then the entire pipeline. This is a really convenient way to test that your tasks are working properly before executing the entire pipeline.

The *TaskRun* can be created from a YAML file, or with `tkn` CLI.

== Pipeline Service Account

OpenShift Pipelines provides a service account, `pipeline`, which gets created in each project by the pipeline operator. The service account is used to run pipelines and tasks. Therefore it needs to have the right permission to access private repositories and private registries as well as all projects that a task or pipeline needs to access.

=== Enabling access to a private Source Code Repository

As a project administrator, you can grant the right permission to the `pipeline` service account in order allow the `git-clone` ClusterTask access to the Gitea source code repository with your credentials.

This is done by create a Kubernetes `secret` to attach to the `pipeline` service account.

. Create the secret *git-secret* of type `kubernetes.io/basic-auth` with your git credentials to your Gitea source code repository:
+
[source,bash,subs="{markup-in-source}",role=execute]
----
oc create secret generic git-secret --from-literal=username=%ocp_username% --from-literal=password=%gitea_password% --type "kubernetes.io/basic-auth" -n pipeline-%guid%
----

. Annotate the secret with the URL of the git server we are using. This helps Tekton match the credentials to the correct git server:
+
[source,bash,subs="{markup-in-source}",role=execute]
----
oc annotate secret git-secret "tekton.dev/git-0=%gitea_url%" -n pipeline-%guid%
----

. Finally attach that secret to `pipeline` service account that will be used by Tekton to execute our tasks. This will allow the `git-clone` ClusterTask to access your private repo on Gitea:
+
[source,bash,subs="{markup-in-source}",role=execute]
----
oc secrets link pipeline git-secret -n pipeline-%guid%
----

. Verify that the secret has been linked:
+
[source,bash,subs="{markup-in-source}",role=execute]
----
oc describe sa pipeline -n pipeline-%guid%
----
+
.Sample Output
[source,options="nowrap",subs="{markup-in-source}"]
----
Name:                pipeline
Namespace:           pipeline-%guid%
Labels:              <none>
Annotations:         <none>
Image pull secrets:  pipeline-dockercfg-k4z7m
Mountable secrets:   pipeline-token-qhq9h
                     pipeline-dockercfg-k4z7m
                     *git-secret*
Tokens:              pipeline-token-h5jq6
                     pipeline-token-qhq9h
Events:              <none>
----

=== Enabling pipeline service account access to a other projects

The Jenkins Pipeline was able to manipulate the _dev_ and _prod_ projects because the `jenkins` service account was already setup with the correct permissions for its _dev_ and _prod_ projects.

You will do the same thing for the OpenShift pipeline, allowing the `pipeline` service account to manipulate the projects *petclinic-%guid%-dev* and *petclinic-%guid%-prod*.

. Ensure that *pipeline-%guid%* project is the active project:
+
[source,bash,subs="{markup-in-source}",role=execute]
----
oc project pipeline-%guid%
----

. Add the `edit` role in *petclinic-%guid%-dev* to all service accounts in project *pipeline-%guid%*:
+
[source,bash,subs="{markup-in-source}",role=execute]
----
oc policy add-role-to-group edit system:serviceaccounts:pipeline-%guid% -n petclinic-%guid%-dev
----

. And add the `edit` role for project *petclinic-%guid%-prod*:
+
[source,bash,subs="{markup-in-source}",role=execute]
----
oc policy add-role-to-group edit system:serviceaccounts:pipeline-%guid% -n petclinic-%guid%-prod
----

== Test tasks individually

One of the nice features of OpenShift pipelines is that you can test each task in the pipeline individually. This happens by creating a *TaskRun* that references a task, specifies the required input and output parameters and optionally specifies a workspace to persist data.

=== Test git-clone Task

First you will execute the first step of the Pipeline, the `git-clone` ClusterTask responsible of cloning our private repository.

If you analyzed the ClusterTask in the previous section, you noticed that thhere it requires three input parameters and a workspace as output:

- *url*: URL of the git repo, use your Gitea ULR: %gitea_url%
- *revision*: branch name, we use `main`
- *deleteExisting*: removes a previous clone if present, `true` in our case

. To run a single task create a new *TaskRun* called `git-clone-taskrun`.
+
[source,bash,subs="{markup-in-source}",role=execute]
----
cat <<'EOF' | oc apply -n pipeline-%guid% -f -
apiVersion: tekton.dev/v1beta1
kind: TaskRun
metadata:
  name: git-clone-taskrun
spec:
  params:
  - name: url
    value: %gitea_url%
  - name: revision
    value: main
  - name: deleteExisting
    value: 'true'
  taskRef:
    kind: ClusterTask
    name: git-clone
  workspaces:
  - name: output
    persistentVolumeClaim:
      claimName: app-source-pvc
EOF
----
+
Creating the *TaskRun* immediately starts the task run.
+
NOTE: In later versions of the Tekton CLI it will be possible to create a TaskRun using the CLI.

. Using the `tkn` command follow the log (it may take a few seconds for log messages to appear):
+
[source,bash,subs="{markup-in-source}",role=execute]
----
tkn taskrun logs -f git-clone-taskrun
----
+
.Sample Output
[source,texinfo]
----
[clone] + CHECKOUT_DIR=/workspace/output/
[clone] + '[[' true '==' true ]]
[clone] + cleandir
[clone] + '[[' -d /workspace/output/ ]]
[clone] + rm -rf '/workspace/output//*'
[clone] + rm -rf /workspace/output//.git
[clone] + rm -rf '/workspace/output//..?*'
[clone] + test -z
[clone] + test -z
[clone] + test -z
[clone] + /ko-app/git-init -url https://gitea-gitea.apps.cluster-8m5j6.8m5j6.sandbox1117.opentlc.com/wkulhane-redhat.
com/spring-petclinic -revision main -refspec  -path /workspace/output/ '-sslVerify=true' '-submodules=true' -depth 1
[clone] {"level":"info","ts":1602704036.4642532,"caller":"git/git.go:136","msg":"Successfully cloned https://gitea-gi
tea.apps.cluster-8m5j6.8m5j6.sandbox1117.opentlc.com/wkulhane-redhat.com/spring-petclinic @ 27109010a52600eb9bf227d63
1fac3f81ed6ba15 (grafted, HEAD, origin/main) in path /workspace/output/"}
[clone] {"level":"info","ts":1602704036.491851,"caller":"git/git.go:177","msg":"Successfully initialized and updated
submodules in path /workspace/output/"}
[clone] + cd /workspace/output/
[clone] + git rev-parse HEAD
[clone] + tr -d '\n'
[clone] + RESULT_SHA=27109010a52600eb9bf227d631fac3f81ed6ba15
[clone] + EXIT_CODE=0
[clone] + '[' 0 '!=' 0 ]
[clone] + echo -n 27109010a52600eb9bf227d631fac3f81ed6ba15
----
+
[TIP]
If you want to run the task again you need to either use a different name for the *TaskRun* object - or delete the previous task run before re-creating it.

=== Test maven build Task

Now execute the second task of our pipeline which builds the Spring boot app using Maven. You will use the `maven` cluster task which requires 2 parameters:

- *GOALS*: the maven goal, in this case `-DskipTests clean package` to just build the application without executing any tests.
- *MAVEN_MIRROR_URL*: the URL of an internal Nexus we can use as a Maven mirror for the app dependencies, we are going to use a Nexus Maven Mirror that is already installed on the cluster. The service URL for the Nexus Maven mirror is http://nexus.nexus.svc:8081/repository/maven-all-public. Note that because this is the URL of the OpenShift service this URL is not accessible from outside the OpenShift cluster (you really don't want to use the Route here - otherwise every request would create additional unneccessary network load).
+
[NOTE]
You will still see that some Spring artifacts are being downloaded from the internet rather than from Nexus. This is because the internal service URL for Nexus is an insecure route (`http`) and the project settings in the source code repo (`pom.xml`) require a secure connection for Spring dependencies.

. Create a *TaskRun* called `maven-taskrun`:
+
[source,bash,subs="{markup-in-source}",role=execute]
----
cat <<'EOF' | oc apply -n pipeline-%guid% -f -
apiVersion: tekton.dev/v1beta1
kind: TaskRun
metadata:
  name: maven-taskrun
spec:
  params:
  - name: GOALS
    value:
    - -DskipTests
    - clean
    - package
  - name: MAVEN_MIRROR_URL
    value: http://nexus.nexus.svc:8081/repository/maven-all-public/
  taskRef:
    kind: ClusterTask
    name: maven
  workspaces:
  - name: source
    persistentVolumeClaim:
      claimName: app-source-pvc
  - name: maven-settings
    emptyDir: {}
EOF
----

. Using the `tkn` command follow the log (it may take a few seconds for log messages to appear):
+
[source,bash,subs="{markup-in-source}",role=execute]
----
tkn taskrun logs -f maven-taskrun
----
+
.Sample Output
[source,texinfo]
----
...
[mvn-goals] Downloaded from mirror.default: http://nexus.nexus.svc:8081/repository/maven-all-public/org/apache/maven/maven-compat/3.0/maven-compat-3.0.jar
 (285 kB at 8.4 MB/s)
[mvn-goals] Downloaded from mirror.default: http://nexus.nexus.svc:8081/repository/maven-all-public/org/tukaani/xz/1.8/xz-1.8.jar (109 kB at 3.1 MB/s)
[mvn-goals] [INFO] Building jar: /workspace/source/target/spring-petclinic-2.3.0.BUILD-SNAPSHOT.jar
[mvn-goals] [INFO]
[mvn-goals] [INFO] --- spring-boot-maven-plugin:2.3.3.RELEASE:repackage (repackage) @ spring-petclinic ---
[mvn-goals] [INFO] Replacing main artifact with repackaged archive
[mvn-goals] [INFO] ------------------------------------------------------------------------
[mvn-goals] [INFO] BUILD SUCCESS
[mvn-goals] [INFO] ------------------------------------------------------------------------
[mvn-goals] [INFO] Total time:  07:10 min
[mvn-goals] [INFO] Finished at: 2020-10-15T13:36:17Z
[mvn-goals] [INFO] ------------------------------------------------------------------------
----
+
Once this task run is completed successfully, your app is built and ready to be packaged into a container and pushed to OpenShift.

In general, if you want to test each task, what you need to do is:

- Create a TaskRun
- Add all required input and output parameters
- If required ensure the Workspace (PersistentVolumeClaim) is present

At this point you are ready to use your `Pipeline`. Pipelines contains a list of Task and ClusterTask, and all pipeline parameters are passed to tasks in the form of `$(params.PARAM_NAME)`.
